{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Disable tokenizers parallelism (avoids deadlock)\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nimport torch\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"GPU:\", torch.cuda.get_device_name(0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:37:46.529026Z","iopub.execute_input":"2025-12-06T10:37:46.529254Z","iopub.status.idle":"2025-12-06T10:37:49.801830Z","shell.execute_reply.started":"2025-12-06T10:37:46.529231Z","shell.execute_reply":"2025-12-06T10:37:49.800945Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q transformers datasets accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:38:01.722940Z","iopub.execute_input":"2025-12-06T10:38:01.723192Z","iopub.status.idle":"2025-12-06T10:39:15.487165Z","shell.execute_reply.started":"2025-12-06T10:38:01.723176Z","shell.execute_reply":"2025-12-06T10:39:15.486427Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_ds = load_dataset(\"Thirteen13tj/Robot-VLA-R1\", split=\"train\")\nraw_ds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:39:17.713734Z","iopub.execute_input":"2025-12-06T10:39:17.714502Z","iopub.status.idle":"2025-12-06T10:39:54.949377Z","shell.execute_reply.started":"2025-12-06T10:39:17.714471Z","shell.execute_reply":"2025-12-06T10:39:54.948753Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"future_prediction_task_video_update.json:   0%|          | 0.00/152M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25a251740c52458994162091da7fc285"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"past_description_task_video_update.json:   0%|          | 0.00/172M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f51164fc1541ea8b0541d8dadc4887"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"planning_remaining_steps_task_video_upda(…):   0%|          | 0.00/193M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2cd6e9ef6e44bdd8416c44c96b2d3b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"planning_task_video_update.json:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b97d8a42a4a641f48c937cd1a9299d56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"planning_with_context_task_video_update.(…):   0%|          | 0.00/156M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7af01d86700f4da8a78b206cd85dc1ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"success_(negative)_task_video_update.jso(…):   0%|          | 0.00/189M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9cf7185f7a540bebb52d52e5ab370f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"success_(positive)_task_video_update.jso(…):   0%|          | 0.00/183M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c89c1399ccb4a9aa124b5d0bfebd1eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/719592 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cbf19bf509247dcbf75a976ee90015d"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['problem_id', 'problem', 'data_type', 'problem_type', 'options', 'process', 'solution', 'path', 'data_source'],\n    num_rows: 719592\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import re\n\ndef extract_answer(solution_str: str):\n    m = re.search(r\"<answer>\\s*(.*?)\\s*</answer>\", solution_str, flags=re.DOTALL)\n    return m.group(1).strip() if m else solution_str.strip()\n\ndef add_text_fields(example):\n    q = example[\"problem\"].strip()\n    a = extract_answer(example[\"solution\"])\n    example[\"input_text\"]  = f\"Question: {q}\\nAnswer:\"\n    example[\"target_text\"] = a\n    return example\n\nraw_ds = raw_ds.map(add_text_fields)\nraw_ds[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:39:59.046218Z","iopub.execute_input":"2025-12-06T10:39:59.046939Z","iopub.status.idle":"2025-12-06T10:41:05.112509Z","shell.execute_reply.started":"2025-12-06T10:39:59.046914Z","shell.execute_reply":"2025-12-06T10:41:05.111799Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/719592 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"491fe82894f345ad8e43c059b77737ce"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'problem_id': 0,\n 'problem': \"After <move the grasped banana towards the mug>, what's the most probable next event?\",\n 'data_type': 'video',\n 'problem_type': 'free-form',\n 'options': [],\n 'process': \"<think>step 1: Grasp the banana\\nreasoning: Before moving the banana towards the mug, the robot must securely grasp the banana to ensure precise control during transportation.\\n\\nstep 2: Move the grasped banana towards the mug\\nreasoning: This is the action already given in the task, positioning the banana close to or above the mug in preparation for placement.\\n\\nstep 3: Position the banana above the mug\\nreasoning: To successfully place the banana into the mug, the banana needs to be aligned properly over the mug's opening or inside the mug, ensuring accurate placement.\\n\\nstep 4: Lower or insert the banana into the mug\\nreasoning: Once properly positioned, the next logical step is to place the banana into the mug, completing the transfer process.\\n\\nFinal step: Place the banana into the mug\\nreasoning: This aligns with the provided solution, completing the task of putting the banana into the mug, which is the most probable next event after moving the banana towards the mug.</think>\",\n 'solution': '<answer><place the banana into the mug></answer>',\n 'path': 'rt_frames_success/rtx_frames_success_42/62_robo_set#episode_1570/video_0.mp4',\n 'data_source': 'RoboLogicTask',\n 'input_text': \"Question: After <move the grasped banana towards the mug>, what's the most probable next event?\\nAnswer:\",\n 'target_text': '<place the banana into the mug>'}"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"MAX_SAMPLES = 50_000\n\nraw_ds_small = raw_ds.shuffle(seed=42).select(range(MAX_SAMPLES))\nraw_ds_small\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:41:19.294371Z","iopub.execute_input":"2025-12-06T10:41:19.294688Z","iopub.status.idle":"2025-12-06T10:41:19.460661Z","shell.execute_reply.started":"2025-12-06T10:41:19.294664Z","shell.execute_reply":"2025-12-06T10:41:19.460058Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['problem_id', 'problem', 'data_type', 'problem_type', 'options', 'process', 'solution', 'path', 'data_source', 'input_text', 'target_text'],\n    num_rows: 50000\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"split = raw_ds_small.train_test_split(test_size=0.01, seed=42)\ntrain_ds = split[\"train\"]\nvalid_ds = split[\"test\"]\n\nlen(train_ds), len(valid_ds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:41:34.167163Z","iopub.execute_input":"2025-12-06T10:41:34.167664Z","iopub.status.idle":"2025-12-06T10:41:34.194608Z","shell.execute_reply.started":"2025-12-06T10:41:34.167640Z","shell.execute_reply":"2025-12-06T10:41:34.193905Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(49500, 500)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"gpt2\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(\"cuda\")\nmodel\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:41:40.276205Z","iopub.execute_input":"2025-12-06T10:41:40.277028Z","iopub.status.idle":"2025-12-06T10:42:13.796942Z","shell.execute_reply.started":"2025-12-06T10:41:40.276998Z","shell.execute_reply":"2025-12-06T10:42:13.796163Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2e0bbd2d9446b5be700b89f7bb9ad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6dc5e74f9154e68b271538ed059add9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1860e220f294d498ec80848f1e5184a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4393746f5144f3aa8444f01545e7337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36355279363e44ad8ea2572edf805652"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-12-06 10:41:54.653132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765017714.806467      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765017714.858183      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3452c7dcaed143699cb8451fb4ec6a6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c9faa6141bf4097b4d32f4c628d95f1"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"MAX_LEN = 128\n\ndef tokenize_batch(batch):\n    texts = [f\"{i} {t}\" for i, t in zip(batch[\"input_text\"], batch[\"target_text\"])]\n    enc = tokenizer(\n        texts,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=MAX_LEN,\n        return_attention_mask=True,\n    )\n    enc[\"labels\"] = enc[\"input_ids\"].copy()\n    return enc\n\ntokenized_train = train_ds.map(tokenize_batch, batched=True, remove_columns=train_ds.column_names)\ntokenized_valid = valid_ds.map(tokenize_batch, batched=True, remove_columns=valid_ds.column_names)\n\ntokenized_train\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:42:21.705946Z","iopub.execute_input":"2025-12-06T10:42:21.707176Z","iopub.status.idle":"2025-12-06T10:42:30.815690Z","shell.execute_reply.started":"2025-12-06T10:42:21.707136Z","shell.execute_reply":"2025-12-06T10:42:30.814837Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/49500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bc42cf88f3642b79d484f74765a9296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9650c0111e948e6a305764309743534"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 49500\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:42:37.135204Z","iopub.execute_input":"2025-12-06T10:42:37.136052Z","iopub.status.idle":"2025-12-06T10:42:37.186221Z","shell.execute_reply.started":"2025-12-06T10:42:37.136017Z","shell.execute_reply":"2025-12-06T10:42:37.185484Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/vla_gpt2\",\n    overwrite_output_dir=True,\n\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=4,\n\n    eval_strategy=\"steps\",\n    eval_steps=1000,\n    save_steps=1000,\n    logging_steps=200,\n\n    learning_rate=5e-5,\n    warmup_ratio=0.03,\n    weight_decay=0.01,\n\n    fp16=True,\n    report_to=\"none\",\n)\ntraining_args\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:42:48.761863Z","iopub.execute_input":"2025-12-06T10:42:48.762148Z","iopub.status.idle":"2025-12-06T10:42:48.847005Z","shell.execute_reply.started":"2025-12-06T10:42:48.762128Z","shell.execute_reply":"2025-12-06T10:42:48.846249Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=1000,\neval_strategy=IntervalStrategy.STEPS,\neval_use_gather_object=False,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=None,\nhub_revision=None,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=5e-05,\nlength_column_name=length,\nliger_kernel_config=None,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=/kaggle/working/vla_gpt2/runs/Dec06_10-42-48_6c25775244bc,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=200,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_kwargs={},\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=1,\noptim=OptimizerNames.ADAMW_TORCH,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=/kaggle/working/vla_gpt2,\noverwrite_output_dir=True,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=4,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=[],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=/kaggle/working/vla_gpt2,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=1000,\nsave_strategy=SaveStrategy.STEPS,\nsave_total_limit=None,\nseed=42,\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.03,\nwarmup_steps=0,\nweight_decay=0.01,\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_valid,\n    data_collator=data_collator,\n)\n\nprint(\"Starting training...\")\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T10:43:05.420831Z","iopub.execute_input":"2025-12-06T10:43:05.421117Z","iopub.status.idle":"2025-12-06T11:02:21.003825Z","shell.execute_reply.started":"2025-12-06T10:43:05.421096Z","shell.execute_reply":"2025-12-06T11:02:21.003192Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3094' max='3094' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3094/3094 19:12, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>0.539200</td>\n      <td>0.515110</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.495200</td>\n      <td>0.486514</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.481400</td>\n      <td>0.477454</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3094, training_loss=0.5738844362935792, metrics={'train_runtime': 1153.5473, 'train_samples_per_second': 42.911, 'train_steps_per_second': 2.682, 'total_flos': 3233488896000000.0, 'train_loss': 0.5738844362935792, 'epoch': 1.0})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"save_dir = \"/kaggle/working/robot_vla_r1_gpt2_final\"\n\nmodel.save_pretrained(save_dir)\ntokenizer.save_pretrained(save_dir)\n\nprint(\"Model saved to:\", save_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T11:02:31.413740Z","iopub.execute_input":"2025-12-06T11:02:31.414436Z","iopub.status.idle":"2025-12-06T11:02:32.359910Z","shell.execute_reply.started":"2025-12-06T11:02:31.414413Z","shell.execute_reply":"2025-12-06T11:02:32.359255Z"}},"outputs":[{"name":"stdout","text":"Model saved to: /kaggle/working/robot_vla_r1_gpt2_final\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!zip -r model_checkpoint.zip /kaggle/working/robot_vla_r1_gpt2_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T11:03:16.984087Z","iopub.execute_input":"2025-12-06T11:03:16.984424Z","iopub.status.idle":"2025-12-06T11:03:42.432958Z","shell.execute_reply.started":"2025-12-06T11:03:16.984403Z","shell.execute_reply":"2025-12-06T11:03:42.432242Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/robot_vla_r1_gpt2_final/ (stored 0%)\n  adding: kaggle/working/robot_vla_r1_gpt2_final/config.json (deflated 51%)\n  adding: kaggle/working/robot_vla_r1_gpt2_final/tokenizer_config.json (deflated 54%)\n  adding: kaggle/working/robot_vla_r1_gpt2_final/generation_config.json (deflated 24%)\n  adding: kaggle/working/robot_vla_r1_gpt2_final/vocab.json (deflated 59%)\n  adding: kaggle/working/robot_vla_r1_gpt2_final/special_tokens_map.json (deflated 60%)\n  adding: kaggle/working/robot_vla_r1_gpt2_final/tokenizer.json (deflated 82%)\n  adding: kaggle/working/robot_vla_r1_gpt2_final/merges.txt (deflated 53%)\n  adding: kaggle/working/robot_vla_r1_gpt2_final/model.safetensors (deflated 7%)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}